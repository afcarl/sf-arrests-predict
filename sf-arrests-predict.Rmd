---
title: "Predicting When and Where Arrests Will Occur in San Francisco with LightGBM"
author: "Max Woolf (@minimaxir)"
date: "January 2nd, 2017"
output:
  html_notebook:
    highlight: tango
    mathjax: null
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
---

This R Notebook is the complement to my blog post [Playing with 80 Million Amazon Product Review Ratings Using Apache Spark](http://minimaxir.com/2017/01/amazon-spark/).

This notebook is licensed under the MIT License. If you use the code or data visualization designs contained within this notebook, it would be greatly appreciated if proper attribution is given back to this notebook and/or myself. Thanks! :)

# Setup

Setup the R packages.

install.packages("/Users/maxwoolf/Downloads/xgboost/R-package", repos = NULL, type="source")

```{r setup}
library(lightgbm)
library(caret)
library(Matrix)

source("Rstart.R")
```

```{r}
sessionInfo()
```

Import data, and only keep relevant columns. Filter on Arrests only.

The data must be randomized for `xgboost` to give unbiased scores. Can do with dplyr's `sample_frac`.

```{r}
file_path <- "~/Downloads/SFPD_Incidents_-_from_1_January_2003.csv"

df <- read_csv(file_path, col_types="_c_ccc_c_nn__") %>%
        filter(grepl("ARREST", Resolution))

# seed for sample_frac()
set.seed(123)

df <- df %>% sample_frac()

df %>% head()
```

# Feature Engineering

Engineer features for `xgboost`.

Categorical Features must be factors for one-hot encoding.

## Month, Hour, Year

```{r}
df <- df %>%
        mutate(month = factor(substring(Date, 1, 2)),
                hour = factor(substring(Time, 1, 2)),
                year = factor(substring(Date, 7, 10)))

df %>% select(month, hour, year) %>% head()
```

## Category Indices

`xgboost` only accepts indices as labels, so map the category to an index. Labels must be zero-indexed.

```{r}
df <- df %>%
        mutate(category_index = as.numeric(factor(Category)) - 1)

df %>% select(category_index, Category) %>% head()
```


## Existing DayOfWeek to Factor

Change DayOfWeek to Factor.

```{r}
df <- df %>%
        mutate(DayOfWeek = factor(DayOfWeek))

df %>% select(DayOfWeek) %>% head()
```


# xgboost Training

Convert the factor variables into dummy variables: `model.matrix()` can do this in R natively. (via [Stack Overflow](http://stackoverflow.com/a/5048727))


```{r}
# model.matrix() adds an Intercept column: the "-1" removes it.
# Matrix converts the dense matrix to sparse (reduces memory footprint to 25%).
train <- Matrix(model.matrix(~ X + Y + hour + month + year + DayOfWeek - 1, df))
num_classes <- length(unique(df$category_index))
num_row <- nrow(train)

train[1:10,]
```

The objective is `multi:softprob` since there are many classes.

Demo: https://github.com/Microsoft/LightGBM/blob/master/R-package/tests/testthat/test_basic.R#L29

```{r}
set.seed(123)

bst <- lightgbm(data = train, label = df$category_index, nrounds = 10, nfold=5, objective = "multiclass", metric="multi_error", num_class=length(unique(df$category_index)))
```

```{r}
preds <- predict(bst, train[1:2,])
preds
length(preds)
```

`preds` is a 1D vector of probabilities for each vector, of nrows x nclasses. Reshape accordingly and iterate through for prediction vectors + probs.

```{r}
preds_matrix <- Matrix(predict(bst, train[1:2,]), byrow=T, num_row, num_classes)

preds_matrix[1:2,]

results <- t(apply(preds_matrix, 1, function (x) {
  max_index = which(x==max(x))
  return (c(max_index-1, x[max_index]))
}))

results
```

